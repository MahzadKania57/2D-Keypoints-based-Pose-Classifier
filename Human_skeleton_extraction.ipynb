{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahzadKania57/2D-Keypoints-based-Pose-Classifier/blob/master/Human_skeleton_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Dataset"
      ],
      "metadata": {
        "id": "Ch9cS0LcAc1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/sample_data/keypoints\"\n",
        "!rm -rf \"/content/sample_data/keypoints_test\""
      ],
      "metadata": {
        "id": "A2_5bw2xxg1j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data\n",
        "!mkdir keypoints\n",
        "%cd keypoints\n",
        "!mkdir raw\n",
        "!mkdir processed\n",
        "%cd raw  \n",
        "!wget https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/X_train.txt \n",
        "!wget https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/Y_train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUHah-pp7Qj6",
        "outputId": "d5b8080d-b265-44f1-b1e7-cee3f6f0a11b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n",
            "/content/sample_data/keypoints\n",
            "/content/sample_data/keypoints/raw\n",
            "--2023-01-21 14:33:37--  https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/X_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 739942 (723K) [text/plain]\n",
            "Saving to: ‘X_train.txt’\n",
            "\n",
            "X_train.txt         100%[===================>] 722.60K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-01-21 14:33:37 (79.4 MB/s) - ‘X_train.txt’ saved [739942/739942]\n",
            "\n",
            "--2023-01-21 14:33:37--  https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/Y_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5352 (5.2K) [text/plain]\n",
            "Saving to: ‘Y_train.txt’\n",
            "\n",
            "Y_train.txt         100%[===================>]   5.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-21 14:33:37 (55.9 MB/s) - ‘Y_train.txt’ saved [5352/5352]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data\n",
        "!mkdir keypoints_test\n",
        "%cd keypoints_test\n",
        "!mkdir raw\n",
        "!mkdir processed\n",
        "%cd raw\n",
        "!wget https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/X_test.txt\n",
        "!wget https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/Y_test.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8DeX_Xtyx5H",
        "outputId": "57da406c-35c7-4468-c462-9cdd73b0815d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n",
            "/content/sample_data/keypoints_test\n",
            "/content/sample_data/keypoints_test/raw\n",
            "--2023-01-21 14:33:38--  https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/X_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 162768 (159K) [text/plain]\n",
            "Saving to: ‘X_test.txt’\n",
            "\n",
            "X_test.txt          100%[===================>] 158.95K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-01-21 14:33:38 (34.3 MB/s) - ‘X_test.txt’ saved [162768/162768]\n",
            "\n",
            "--2023-01-21 14:33:38--  https://raw.githubusercontent.com/tringn/2D-Keypoints-based-Pose-Classifier/master/dataset/Y_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1402 (1.4K) [text/plain]\n",
            "Saving to: ‘Y_test.txt’\n",
            "\n",
            "Y_test.txt          100%[===================>]   1.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-21 14:33:38 (20.5 MB/s) - ‘Y_test.txt’ saved [1402/1402]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**load_joints**"
      ],
      "metadata": {
        "id": "t_KQ30SLAls7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def euclidean_dist(a, b):\n",
        "    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n",
        "    # if one of two points is (0,0), dist = 0\n",
        "    # a, b: input array with dimension: m, 2\n",
        "    # m: number of samples\n",
        "    # 2: x and y coordinate\n",
        "    try:\n",
        "        if (a.shape[1] == 2 and a.shape == b.shape):\n",
        "            # check if element of a and b is (0,0)\n",
        "            bol_a = (a[:,0] != 0).astype(int)\n",
        "            bol_b = (b[:,0] != 0).astype(int)\n",
        "            dist = np.linalg.norm(a-b, axis=1)\n",
        "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
        "    except:\n",
        "        print(\"[Error]: Check dimension of input vector\")\n",
        "        return 0\n",
        "    \n",
        "def load_X(X_path):\n",
        "    file = open(X_path, 'r')\n",
        "    X_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.split(',') for row in file\n",
        "        ]], \n",
        "        dtype=np.float32\n",
        "    )\n",
        "    file.close()\n",
        "    return X_\n",
        "\n",
        "def load_Y(y_path):\n",
        "    file = open(y_path, 'r')\n",
        "    y_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
        "        ]], \n",
        "        dtype=np.int32\n",
        "    )\n",
        "    file.close()\n",
        "    return y_\n",
        "  \n",
        " \n",
        "def norm_X(X):\n",
        "    num_sample = X.shape[0]\n",
        "    # Keypoints\n",
        "    Nose = X[:,0*2:0*2+2]\n",
        "    Neck = X[:,1*2:1*2+2]\n",
        "    RShoulder = X[:,2*2:2*2+2]\n",
        "    RElbow = X[:,3*2:3*2+2]\n",
        "    RWrist = X[:,4*2:4*2+2]\n",
        "    LShoulder = X[:,5*2:5*2+2]\n",
        "    LElbow = X[:,6*2:6*2+2]\n",
        "    LWrist = X[:,7*2:7*2+2]\n",
        "    RHip = X[:,8*2:8*2+2]\n",
        "    RKnee = X[:,9*2:9*2+2]\n",
        "    RAnkle = X[:,10*2:10*2+2]\n",
        "    LHip = X[:,11*2:11*2+2]\n",
        "    LKnee = X[:,12*2:12*2+2]\n",
        "    LAnkle = X[:,13*2:13*2+2]\n",
        "    REye = X[:,14*2:14*2+2]\n",
        "    LEye = X[:,15*2:15*2+2]\n",
        "    REar = X[:,16*2:16*2+2]\n",
        "    LEar = X[:,17*2:17*2+2]\n",
        "\n",
        "    # Length of head\n",
        "    length_Neck_LEar = euclidean_dist(Neck, LEar)\n",
        "    length_Neck_REar = euclidean_dist(Neck, REar)\n",
        "    length_Neck_LEye = euclidean_dist(Neck, LEye)\n",
        "    length_Neck_REye = euclidean_dist(Neck, REye)\n",
        "    length_Nose_LEar = euclidean_dist(Nose, LEar)\n",
        "    length_Nose_REar = euclidean_dist(Nose, REar)\n",
        "    length_Nose_LEye = euclidean_dist(Nose, LEye)\n",
        "    length_Nose_REye = euclidean_dist(Nose, REye)\n",
        "    length_head      = np.maximum.reduce([length_Neck_LEar, length_Neck_REar, length_Neck_LEye, length_Neck_REye, \\\n",
        "                                 length_Nose_LEar, length_Nose_REar, length_Nose_LEye, length_Nose_REye])\n",
        "    #length_head      = np.sqrt(np.square((LEye[:,0:1]+REye[:,0:1])/2 - Neck[:,0:1]) + np.square((LEye[:,1:2]+REye[:,1:2])/2 - Neck[:,1:2]))\n",
        "\n",
        "    # Length of torso\n",
        "    length_Neck_LHip = euclidean_dist(Neck, LHip)\n",
        "    length_Neck_RHip = euclidean_dist(Neck, RHip)\n",
        "    length_torso     = np.maximum(length_Neck_LHip, length_Neck_RHip)\n",
        "    #length_torso     = np.sqrt(np.square(Neck[:,0:1]-(LHip[:,0:1]+RHip[:,0:1])/2) + np.square(Neck[:,1:2]-(LHip[:,1:2]+RHip[:,1:2])/2))\n",
        "\n",
        "    # Length of right leg\n",
        "    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n",
        "    #length_leg_right = np.sqrt(np.square(RHip[:,0:1]-RKnee[:,0:1]) + np.square(RHip[:,1:2]-RKnee[:,1:2])) \\\n",
        "    #+ np.sqrt(np.square(RKnee[:,0:1]-RAnkle[:,0:1]) + np.square(RKnee[:,1:2]-RAnkle[:,1:2]))\n",
        "\n",
        "    # Length of left leg\n",
        "    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n",
        "    #length_leg_left = np.sqrt(np.square(LHip[:,0:1]-LKnee[:,0:1]) + np.square(LHip[:,1:2]-LKnee[:,1:2])) \\\n",
        "    #+ np.sqrt(np.square(LKnee[:,0:1]-LAnkle[:,0:1]) + np.square(LKnee[:,1:2]-LAnkle[:,1:2]))\n",
        "\n",
        "    # Length of leg\n",
        "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
        "\n",
        "    # Length of body\n",
        "    length_body = length_head + length_torso + length_leg\n",
        "    \n",
        "    # Check all samples have length_body of 0\n",
        "    length_chk = (length_body > 0).astype(int)\n",
        "    \n",
        "    # Check keypoints at origin\n",
        "    keypoints_chk = (X > 0).astype(int)\n",
        "    \n",
        "    chk = length_chk * keypoints_chk\n",
        "    \n",
        "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
        "    length_body[length_body == 0] = 1\n",
        "    \n",
        "    # The center of gravity\n",
        "    # number of point OpenPose locates:\n",
        "    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n",
        "    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n",
        "    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n",
        "\n",
        "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
        "    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n",
        "    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n",
        "    \n",
        "    # Stack 1st element x and y together\n",
        "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n",
        "        \n",
        "    for i in range(1, X.shape[1]//2):\n",
        "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n",
        "    \n",
        "    # Set all samples have length_body of 0 to origin (0, 0)\n",
        "    X_norm = X_norm * chk\n",
        "    \n",
        "    return X_norm"
      ],
      "metadata": {
        "id": "bmGzbvDAW4Mq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create edge_index**"
      ],
      "metadata": {
        "id": "EposkOv0AuG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csc_matrix\n",
        "import torch"
      ],
      "metadata": {
        "id": "npBffrnuKxXd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create sparse matrix\n",
        "i = np.array([0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 6, 6, 7, 8, 8, 9, 9, 10, 11, 11, 12, 12, 13])\n",
        "j = np.array([1, 0, 2, 5, 8, 11, 1, 3, 2, 4, 3, 1, 6, 5, 7, 6, 1, 9, 8, 10, 9, 1, 12, 11, 13, 12])\n",
        "\n",
        "\n",
        "degree = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ],
      "metadata": {
        "id": "Zg4zpJr8cJho"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = csc_matrix((degree, (i, j)), shape = (14, 14)).tocoo()"
      ],
      "metadata": {
        "id": "7SHtKx9DG3gz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtlkwKI7N085",
        "outputId": "79beb215-0d3b-4708-bead-0ca987827110"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAAlhl9IG6tt",
        "outputId": "b9e33bc2-d265-479a-8e7e-9cd5afa730e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (1, 0)\t1\n",
            "  (0, 1)\t1\n",
            "  (2, 1)\t1\n",
            "  (5, 1)\t1\n",
            "  (8, 1)\t1\n",
            "  (11, 1)\t1\n",
            "  (1, 2)\t1\n",
            "  (3, 2)\t1\n",
            "  (2, 3)\t1\n",
            "  (4, 3)\t1\n",
            "  (3, 4)\t1\n",
            "  (1, 5)\t1\n",
            "  (6, 5)\t1\n",
            "  (5, 6)\t1\n",
            "  (7, 6)\t1\n",
            "  (6, 7)\t1\n",
            "  (1, 8)\t1\n",
            "  (9, 8)\t1\n",
            "  (8, 9)\t1\n",
            "  (10, 9)\t1\n",
            "  (9, 10)\t1\n",
            "  (1, 11)\t1\n",
            "  (12, 11)\t1\n",
            "  (11, 12)\t1\n",
            "  (13, 12)\t1\n",
            "  (12, 13)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.from_numpy(i).to(torch.long)\n",
        "j = torch.from_numpy(j).to(torch.long)"
      ],
      "metadata": {
        "id": "EcdJlZXOAmml"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index =  torch.stack([i,j], dim=0)"
      ],
      "metadata": {
        "id": "Y03CnvEZApDq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Dataset**"
      ],
      "metadata": {
        "id": "-_-gFnX9iaiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58F6DKdFHIBV",
        "outputId": "6b171ddb-4e00-41ac-e9d4-2c80b05279ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "W7g-fRSY3eko"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkeletonDataset(Dataset):\n",
        "    def __init__(self, root, x_root, y_root):\n",
        "      self.x_root = x_root\n",
        "      self.y_root = y_root\n",
        "      super().__init__(root)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "      return [self.x_root, self.y_root]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "      return \"data.pt\"\n",
        "        \n",
        "\n",
        "    def process(self):\n",
        "      X_ = load_X(self.raw_paths[0])\n",
        "      Y = load_Y(self.raw_paths[1])\n",
        "\n",
        "      X = norm_X(X_)\n",
        "      X = X.reshape(X.shape[0], -1, 2)\n",
        "      X = X[:, :14, :]\n",
        "\n",
        "      self.X = torch.from_numpy(X).to(torch.float)\n",
        "      self.Y = torch.from_numpy(Y).to(torch.long)\n",
        "      idx = 0\n",
        "      for i in range(0, X.shape[0]):\n",
        "        # Read data\n",
        "        data = Data(x= self.X[i], edge_index=edge_index, y=self.Y[i])\n",
        "        torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        idx += 1\n",
        "\n",
        "    def len(self):\n",
        "      return self.X.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "      data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "      return data"
      ],
      "metadata": {
        "id": "YrKMKdJefguj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SkeletonDataset(root='/content/sample_data/keypoints/', x_root='X_train.txt', y_root='Y_train.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZZTgt1agcsH",
        "outputId": "fc6a763c-fc3e-499e-97da-d977e582371e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SkeletonDataset(root='/content/sample_data/keypoints_test', x_root='X_test.txt', y_root='Y_test.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vf3sicn2JKO",
        "outputId": "583cf3b8-f53d-4b87-d7d7-b083e3494114"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.len(), test_dataset.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3h4dsgr8wVc",
        "outputId": "9418d230-928b-41c4-d798-64dbd7f7e774"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2676, 701)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "cdJ0U_rR91cm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, data in enumerate(test_loader):\n",
        "  print(f'Step {step + 1}:')\n",
        "  print('=======')\n",
        "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "  print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMuIEBQb-UKu",
        "outputId": "9ea36f55-7b47-4fe1-c336-b8667c7e69bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 3:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 4:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 5:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 6:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 7:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 8:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 9:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 10:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[896, 2], edge_index=[2, 1664], y=[64], batch=[896], ptr=[65])\n",
            "Step 11:\n",
            "=======\n",
            "Number of graphs in the current batch: 61\n",
            "DataBatch(x=[854, 2], edge_index=[2, 1586], y=[61], batch=[854], ptr=[62])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Graph**"
      ],
      "metadata": {
        "id": "UWkyupWzeOr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "U6_ZALt6ajV_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def norm2pix(norm):\n",
        "  return int((norm*256) + 256)"
      ],
      "metadata": {
        "id": "U-9LuUglmDaN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_graph(nodes, edge_index):\n",
        "  img = np.ones((512,512), dtype=np.uint8)\n",
        "  \n",
        "  color = (255, 255, 255)\n",
        "\n",
        "  #draw points\n",
        "  for i in range(nodes.shape[1]):\n",
        "   cv2.circle(img, (norm2pix(nodes[i][0]), norm2pix(nodes[i][0])), 4, (255, 255, 255), -1)\n",
        "\n",
        "  #draw lines\n",
        "  for i in range(edge_index.shape[1]):\n",
        "\n",
        "    start_node = edge_index[0][i]\n",
        "    end_node = edge_index[1][i]\n",
        "\n",
        "    p1 = norm2pix(nodes[start_node, 0]), norm2pix(nodes[start_node, 1])\n",
        "    p2 = norm2pix(nodes[end_node, 0]), norm2pix(nodes[end_node, 1])\n",
        "    cv2.line(img, p1, p2, color, thickness=2, lineType=cv2.LINE_AA)\n",
        "\n",
        "  #display image\n",
        "  cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "YqFmZWZnemyk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_graph(train_dataset[30].x, edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "uxkB2Tdkhaw2",
        "outputId": "567be6c6-0709-49b2-bfb5-50b80aad8de5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=512x512 at 0x7FD331C50970>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train The Graph convolution Network**"
      ],
      "metadata": {
        "id": "Lrn1FkdziDGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool"
      ],
      "metadata": {
        "id": "8TIP3ZWQiRcR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels, num_node_features, num_classes):\n",
        "    super().__init__()\n",
        "    torch.manual_seed(12345)\n",
        "\n",
        "    self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "    self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "    self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "    self.lin = Linear(hidden_channels, num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    #1. Obtain node embeddings\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv3(x, edge_index)\n",
        "\n",
        "    #2. Readout layers(get graph embeddings)\n",
        "    x = global_mean_pool(x, batch) #[batch-size, hidden_channels]\n",
        "  \n",
        "    #3. Apply a final classifier\n",
        "    x = F.dropout(x, p=0.5, training= self.training)\n",
        "    x = self.lin(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "JIj12UYgiXmg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(64, train_dataset.num_node_features, train_dataset.num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "culTlJ7xA_Od"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9mwbIABBKLi",
        "outputId": "c223f692-1f3f-4b60-b104-bd0b0f7f5421"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(2, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  model.train()\n",
        "\n",
        "  for data in train_loader:\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    loss.backward()  # Derive gradients.\n",
        "    optimizer.step()  # Update parameters based on gradients.\n",
        "    optimizer.zero_grad() # Clear gradients."
      ],
      "metadata": {
        "id": "SCmIpUDRBMwz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  for data in loader:\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += int((pred == data.y).sum())\n",
        "  return correct/len(loader.dataset)"
      ],
      "metadata": {
        "id": "-HyLujKsBqeG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 165):\n",
        "  train()\n",
        "  train_acc = test(train_loader)\n",
        "  test_acc = test(test_loader)\n",
        "  print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrKxla2pB8rU",
        "outputId": "1ef8bbde-4e41-49ce-8a6f-505ba73cdf17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.8345, Test Acc: 0.8046\n",
            "Epoch: 002, Train Acc: 0.8528, Test Acc: 0.8317\n",
            "Epoch: 003, Train Acc: 0.8184, Test Acc: 0.7960\n",
            "Epoch: 004, Train Acc: 0.8737, Test Acc: 0.8445\n",
            "Epoch: 005, Train Acc: 0.8595, Test Acc: 0.8417\n",
            "Epoch: 006, Train Acc: 0.8718, Test Acc: 0.8759\n",
            "Epoch: 007, Train Acc: 0.8774, Test Acc: 0.8616\n",
            "Epoch: 008, Train Acc: 0.8827, Test Acc: 0.8702\n",
            "Epoch: 009, Train Acc: 0.8068, Test Acc: 0.8003\n",
            "Epoch: 010, Train Acc: 0.8782, Test Acc: 0.8702\n",
            "Epoch: 011, Train Acc: 0.8883, Test Acc: 0.8745\n",
            "Epoch: 012, Train Acc: 0.9028, Test Acc: 0.8944\n",
            "Epoch: 013, Train Acc: 0.8804, Test Acc: 0.8616\n",
            "Epoch: 014, Train Acc: 0.8363, Test Acc: 0.8388\n",
            "Epoch: 015, Train Acc: 0.8322, Test Acc: 0.8274\n",
            "Epoch: 016, Train Acc: 0.9010, Test Acc: 0.8887\n",
            "Epoch: 017, Train Acc: 0.9006, Test Acc: 0.8916\n",
            "Epoch: 018, Train Acc: 0.8868, Test Acc: 0.8730\n",
            "Epoch: 019, Train Acc: 0.9122, Test Acc: 0.9030\n",
            "Epoch: 020, Train Acc: 0.8991, Test Acc: 0.8987\n",
            "Epoch: 021, Train Acc: 0.9133, Test Acc: 0.9030\n",
            "Epoch: 022, Train Acc: 0.8946, Test Acc: 0.8916\n",
            "Epoch: 023, Train Acc: 0.8812, Test Acc: 0.9044\n",
            "Epoch: 024, Train Acc: 0.9204, Test Acc: 0.9201\n",
            "Epoch: 025, Train Acc: 0.9107, Test Acc: 0.9058\n",
            "Epoch: 026, Train Acc: 0.9163, Test Acc: 0.9058\n",
            "Epoch: 027, Train Acc: 0.9129, Test Acc: 0.9101\n",
            "Epoch: 028, Train Acc: 0.8662, Test Acc: 0.8559\n",
            "Epoch: 029, Train Acc: 0.9197, Test Acc: 0.9101\n",
            "Epoch: 030, Train Acc: 0.9152, Test Acc: 0.9001\n",
            "Epoch: 031, Train Acc: 0.9058, Test Acc: 0.9030\n",
            "Epoch: 032, Train Acc: 0.9032, Test Acc: 0.9016\n",
            "Epoch: 033, Train Acc: 0.9047, Test Acc: 0.9001\n",
            "Epoch: 034, Train Acc: 0.9144, Test Acc: 0.9030\n",
            "Epoch: 035, Train Acc: 0.9182, Test Acc: 0.8973\n",
            "Epoch: 036, Train Acc: 0.9178, Test Acc: 0.8987\n",
            "Epoch: 037, Train Acc: 0.9286, Test Acc: 0.9244\n",
            "Epoch: 038, Train Acc: 0.9092, Test Acc: 0.9058\n",
            "Epoch: 039, Train Acc: 0.9223, Test Acc: 0.9215\n",
            "Epoch: 040, Train Acc: 0.8419, Test Acc: 0.8274\n",
            "Epoch: 041, Train Acc: 0.9141, Test Acc: 0.9001\n",
            "Epoch: 042, Train Acc: 0.9051, Test Acc: 0.9044\n",
            "Epoch: 043, Train Acc: 0.9088, Test Acc: 0.8944\n",
            "Epoch: 044, Train Acc: 0.9245, Test Acc: 0.9116\n",
            "Epoch: 045, Train Acc: 0.9200, Test Acc: 0.9044\n",
            "Epoch: 046, Train Acc: 0.9204, Test Acc: 0.9258\n",
            "Epoch: 047, Train Acc: 0.9241, Test Acc: 0.9187\n",
            "Epoch: 048, Train Acc: 0.9055, Test Acc: 0.8845\n",
            "Epoch: 049, Train Acc: 0.9137, Test Acc: 0.9116\n",
            "Epoch: 050, Train Acc: 0.9342, Test Acc: 0.9244\n",
            "Epoch: 051, Train Acc: 0.9320, Test Acc: 0.9215\n",
            "Epoch: 052, Train Acc: 0.9327, Test Acc: 0.9158\n",
            "Epoch: 053, Train Acc: 0.9241, Test Acc: 0.9116\n",
            "Epoch: 054, Train Acc: 0.9283, Test Acc: 0.9230\n",
            "Epoch: 055, Train Acc: 0.9297, Test Acc: 0.9158\n",
            "Epoch: 056, Train Acc: 0.8879, Test Acc: 0.8845\n",
            "Epoch: 057, Train Acc: 0.9215, Test Acc: 0.9030\n",
            "Epoch: 058, Train Acc: 0.9241, Test Acc: 0.9130\n",
            "Epoch: 059, Train Acc: 0.9316, Test Acc: 0.9215\n",
            "Epoch: 060, Train Acc: 0.9320, Test Acc: 0.9244\n",
            "Epoch: 061, Train Acc: 0.8886, Test Acc: 0.8659\n",
            "Epoch: 062, Train Acc: 0.9271, Test Acc: 0.9030\n",
            "Epoch: 063, Train Acc: 0.9219, Test Acc: 0.9030\n",
            "Epoch: 064, Train Acc: 0.8871, Test Acc: 0.8816\n",
            "Epoch: 065, Train Acc: 0.9275, Test Acc: 0.9330\n",
            "Epoch: 066, Train Acc: 0.9286, Test Acc: 0.9130\n",
            "Epoch: 067, Train Acc: 0.9268, Test Acc: 0.9058\n",
            "Epoch: 068, Train Acc: 0.9376, Test Acc: 0.9244\n",
            "Epoch: 069, Train Acc: 0.9410, Test Acc: 0.9230\n",
            "Epoch: 070, Train Acc: 0.9309, Test Acc: 0.9116\n",
            "Epoch: 071, Train Acc: 0.9354, Test Acc: 0.9130\n",
            "Epoch: 072, Train Acc: 0.9365, Test Acc: 0.9144\n",
            "Epoch: 073, Train Acc: 0.9387, Test Acc: 0.9201\n",
            "Epoch: 074, Train Acc: 0.9320, Test Acc: 0.9030\n",
            "Epoch: 075, Train Acc: 0.9256, Test Acc: 0.8973\n",
            "Epoch: 076, Train Acc: 0.9402, Test Acc: 0.9315\n",
            "Epoch: 077, Train Acc: 0.9357, Test Acc: 0.9187\n",
            "Epoch: 078, Train Acc: 0.9357, Test Acc: 0.9073\n",
            "Epoch: 079, Train Acc: 0.9391, Test Acc: 0.9258\n",
            "Epoch: 080, Train Acc: 0.9174, Test Acc: 0.8973\n",
            "Epoch: 081, Train Acc: 0.9331, Test Acc: 0.9173\n",
            "Epoch: 082, Train Acc: 0.9346, Test Acc: 0.9173\n",
            "Epoch: 083, Train Acc: 0.9324, Test Acc: 0.9087\n",
            "Epoch: 084, Train Acc: 0.9368, Test Acc: 0.9415\n",
            "Epoch: 085, Train Acc: 0.9253, Test Acc: 0.9144\n",
            "Epoch: 086, Train Acc: 0.9331, Test Acc: 0.9158\n",
            "Epoch: 087, Train Acc: 0.9417, Test Acc: 0.9130\n",
            "Epoch: 088, Train Acc: 0.9398, Test Acc: 0.9201\n",
            "Epoch: 089, Train Acc: 0.9398, Test Acc: 0.9258\n",
            "Epoch: 090, Train Acc: 0.9342, Test Acc: 0.9144\n",
            "Epoch: 091, Train Acc: 0.9447, Test Acc: 0.9272\n",
            "Epoch: 092, Train Acc: 0.9354, Test Acc: 0.9287\n",
            "Epoch: 093, Train Acc: 0.9395, Test Acc: 0.9101\n",
            "Epoch: 094, Train Acc: 0.9141, Test Acc: 0.9044\n",
            "Epoch: 095, Train Acc: 0.9466, Test Acc: 0.9173\n",
            "Epoch: 096, Train Acc: 0.9279, Test Acc: 0.9173\n",
            "Epoch: 097, Train Acc: 0.9316, Test Acc: 0.9187\n",
            "Epoch: 098, Train Acc: 0.9383, Test Acc: 0.9230\n",
            "Epoch: 099, Train Acc: 0.9410, Test Acc: 0.9215\n",
            "Epoch: 100, Train Acc: 0.9488, Test Acc: 0.9287\n",
            "Epoch: 101, Train Acc: 0.9331, Test Acc: 0.9173\n",
            "Epoch: 102, Train Acc: 0.9398, Test Acc: 0.9230\n",
            "Epoch: 103, Train Acc: 0.9477, Test Acc: 0.9344\n",
            "Epoch: 104, Train Acc: 0.9339, Test Acc: 0.9287\n",
            "Epoch: 105, Train Acc: 0.9488, Test Acc: 0.9244\n",
            "Epoch: 106, Train Acc: 0.9447, Test Acc: 0.9187\n",
            "Epoch: 107, Train Acc: 0.9395, Test Acc: 0.9158\n",
            "Epoch: 108, Train Acc: 0.9226, Test Acc: 0.9001\n",
            "Epoch: 109, Train Acc: 0.9406, Test Acc: 0.9158\n",
            "Epoch: 110, Train Acc: 0.9354, Test Acc: 0.9044\n",
            "Epoch: 111, Train Acc: 0.9372, Test Acc: 0.9116\n",
            "Epoch: 112, Train Acc: 0.9473, Test Acc: 0.9130\n",
            "Epoch: 113, Train Acc: 0.9436, Test Acc: 0.9272\n",
            "Epoch: 114, Train Acc: 0.9365, Test Acc: 0.9130\n",
            "Epoch: 115, Train Acc: 0.9439, Test Acc: 0.9272\n",
            "Epoch: 116, Train Acc: 0.9417, Test Acc: 0.9272\n",
            "Epoch: 117, Train Acc: 0.9283, Test Acc: 0.9101\n",
            "Epoch: 118, Train Acc: 0.9462, Test Acc: 0.9215\n",
            "Epoch: 119, Train Acc: 0.9469, Test Acc: 0.9230\n",
            "Epoch: 120, Train Acc: 0.8972, Test Acc: 0.8787\n",
            "Epoch: 121, Train Acc: 0.9410, Test Acc: 0.9215\n",
            "Epoch: 122, Train Acc: 0.9458, Test Acc: 0.9258\n",
            "Epoch: 123, Train Acc: 0.9537, Test Acc: 0.9244\n",
            "Epoch: 124, Train Acc: 0.9002, Test Acc: 0.9044\n",
            "Epoch: 125, Train Acc: 0.9540, Test Acc: 0.9387\n",
            "Epoch: 126, Train Acc: 0.9391, Test Acc: 0.9116\n",
            "Epoch: 127, Train Acc: 0.9499, Test Acc: 0.9258\n",
            "Epoch: 128, Train Acc: 0.9391, Test Acc: 0.9030\n",
            "Epoch: 129, Train Acc: 0.9462, Test Acc: 0.9173\n",
            "Epoch: 130, Train Acc: 0.9354, Test Acc: 0.9230\n",
            "Epoch: 131, Train Acc: 0.9496, Test Acc: 0.9201\n",
            "Epoch: 132, Train Acc: 0.9529, Test Acc: 0.9287\n",
            "Epoch: 133, Train Acc: 0.9469, Test Acc: 0.9201\n",
            "Epoch: 134, Train Acc: 0.9421, Test Acc: 0.9030\n",
            "Epoch: 135, Train Acc: 0.9417, Test Acc: 0.9144\n",
            "Epoch: 136, Train Acc: 0.9092, Test Acc: 0.8773\n",
            "Epoch: 137, Train Acc: 0.9544, Test Acc: 0.9287\n",
            "Epoch: 138, Train Acc: 0.9529, Test Acc: 0.9287\n",
            "Epoch: 139, Train Acc: 0.8957, Test Acc: 0.8730\n",
            "Epoch: 140, Train Acc: 0.9466, Test Acc: 0.9187\n",
            "Epoch: 141, Train Acc: 0.9540, Test Acc: 0.9287\n",
            "Epoch: 142, Train Acc: 0.9368, Test Acc: 0.9073\n",
            "Epoch: 143, Train Acc: 0.9518, Test Acc: 0.9230\n",
            "Epoch: 144, Train Acc: 0.9451, Test Acc: 0.9215\n",
            "Epoch: 145, Train Acc: 0.9361, Test Acc: 0.9030\n",
            "Epoch: 146, Train Acc: 0.9159, Test Acc: 0.9001\n",
            "Epoch: 147, Train Acc: 0.9499, Test Acc: 0.9287\n",
            "Epoch: 148, Train Acc: 0.9439, Test Acc: 0.9272\n",
            "Epoch: 149, Train Acc: 0.9567, Test Acc: 0.9258\n",
            "Epoch: 150, Train Acc: 0.9402, Test Acc: 0.9101\n",
            "Epoch: 151, Train Acc: 0.9540, Test Acc: 0.9130\n",
            "Epoch: 152, Train Acc: 0.9552, Test Acc: 0.9258\n",
            "Epoch: 153, Train Acc: 0.9458, Test Acc: 0.9301\n",
            "Epoch: 154, Train Acc: 0.9462, Test Acc: 0.9101\n",
            "Epoch: 155, Train Acc: 0.9473, Test Acc: 0.9272\n",
            "Epoch: 156, Train Acc: 0.9256, Test Acc: 0.8930\n",
            "Epoch: 157, Train Acc: 0.9421, Test Acc: 0.9116\n",
            "Epoch: 158, Train Acc: 0.9118, Test Acc: 0.9016\n",
            "Epoch: 159, Train Acc: 0.9301, Test Acc: 0.8987\n",
            "Epoch: 160, Train Acc: 0.9395, Test Acc: 0.9030\n",
            "Epoch: 161, Train Acc: 0.9425, Test Acc: 0.9258\n",
            "Epoch: 162, Train Acc: 0.9525, Test Acc: 0.9272\n",
            "Epoch: 163, Train Acc: 0.9294, Test Acc: 0.9087\n",
            "Epoch: 164, Train Acc: 0.9533, Test Acc: 0.9173\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EposkOv0AuG8"
      ],
      "authorship_tag": "ABX9TyM0Uuut0HzTuKbfZ63fW0RP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}